---
title: AI weekly (04/2020)
subtitle: My selection of news on AI/ML and Data Science
date: 2020-01-25
# lastmod: 2020-01-21
bigimg: [{src: "/img/2020-01-25-ai-weekly-04-2020.jpg", desc: "Kleinmachnow (2020)"}]
tags: ["ai-news", "baidu", "bert", "google", "kubernetes", "microsoft", "onnx", "sound-analysis", "spark"]
---

+++  Microsoft open sources BERT optimizations in ONNX runtime +++ Why Google thinks we need to regulate AI +++ A Look Back on Baidu’s AI Innovations in 2019 +++ An introduction to audio data analysis using Python +++ Spark in Docker in Kubernetes: A practical approach for scalable NLP +++
 
<!--more-->

## Breakthrough &mdash; Or So They Say


 


## Tools and Frameworks

**Microsoft open sources BERT optimizations in ONNX runtime.** Microsoft has announced in a [blog post](https://cloudblogs.microsoft.com/opensource/2020/01/21/microsoft-onnx-open-source-optimizations-transformer-inference-gpu-cpu/) this week that it has integrated an optimized implementation of BERT (Bidirectional Encoder Representations from Transformers) with the open source ONNX Runtime. Developers can take advantage of this implementation for scalable inferencing of BERT at an affordable cost. In 2018, Google had [open sourced BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) as a new technique for pre-training NLP models, revolutionizing the conversational user experience domain by empowering developers to train their own state-of-the-art question answering system and a variety of other natural language-based models. Recently, [Microsoft has shared](https://azure.microsoft.com/en-us/blog/bing-delivers-its-largest-improvement-in-search-experience-using-azure-gpus/) how Bing has improved BERT inference on GPU for its real-time service needs, serving more than one million BERT inferences per second within Bing’s latency limits. An enhanced versions, working on both GPU and CPU, was now open sourced into the [ONNX Runtime on github](https://github.com/microsoft/onnxruntime/releases/tag/v1.1.1). The Open Neural Network Exchange (ONNX) is an open standard format for representing machine learning models, making it possible to exchange models between frameworks such as [Tensorflow](https://github.com/tensorflow/tensorflow), [PyTorch](https://github.com/pytorch/pytorch) or [MXNet](https://github.com/apache/incubator-mxnet). It lives on [github](https://github.com/onnx/onnx) and comes with [tutorials](https://github.com/onnx/tutorials) and a [model zoo](https://github.com/onnx/models).


## Business News and Applications

**Why Google thinks we need to regulate AI.** Google and Alphabet CEO Sundar Pichai has laid out his case for greater regulation of AI. In an op-ed for the [Financial Times](https://www.ft.com/content/3467659a-386d-11ea-ac3c-f68c10993b04), he highlighted the perils of “nefarious uses of facial recognition” as well as deepfakes. His message to policymakers: “Sensible regulation must also take a proportionate approach” to artificial intelligence, “balancing potential harms with social opportunities. There is no question in my mind that artificial intelligence needs to be regulated. [...] The question is how best to approach this.” Currently, US and EU plans for AI regulation seem to be diverging. While the White House is advocating for light-touch regulation that avoids “overreach” in order to encourage innovation, the EU is considering more direct intervention, such as a five-year ban on facial recognition. Pichai called for lawmakers to get on the same page. “International alignment will be critical to making global standards work,” he wrote. “To get there, we need agreement on core values.” Simultaneously, the pitch downplays any negatives that might cloud the greater good that Pichai implies AI will unlock. And, not surprisingly, there is no hint at the concentration of monopoly power that AI appears to be very good at supporting.

**A Look Back on Baidu’s AI Innovations in 2019.** Baidu highlights some of their key achievement in 2019 in a [post on their research blog](http://research.baidu.com/Blog/index-view?id=130). Baidu ranked No.1 in the number of AI-related patent applications in China for the second consecutive year, filing a total of 5,712 patents as of October 2019. Deep learning (1,429), natural language processing (938), and speech recognition (933) account for almost 60 percent of those patent applications. Among the technologies and applications they highlight are their NLP framework [Ernie](http://research.baidu.com/Blog/index-view?id=121), hardware accelerators for AI workloads, their [presence in quantum computing](https://quanlse.baidu.com/en/), visual perception modules for autonomous vehicles, and their open-sourced deep learning platform PaddlePaddle. 



## Publications




## Tutorials

**An introduction to audio data analysis using Python.** This [article on Towards Data Science](https://towardsdatascience.com/understanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520) provides a step-wise guide to start with audio data processing, or sound analysis, along with Python code. Topics covered are reading audio files, Fourier and Fast Fourier transforms, spectrograms and, finally, performing speech recognition using spectrogram features.

**Spark in Docker in Kubernetes: A practical approach for scalable NLP.** The processing of written language can be very complex and can take a long time without scalable architecture. Instead of going for ever faster processors, it is better to choose an architecture which can distribute the computing load over several machines. [This article on Towards Data Science](https://towardsdatascience.com/spark-in-docker-in-kubernetes-a-practical-approach-for-scalable-nlp-9dd6ef47c31e), as the title says, leverages Spark in Docker on Kubernetes, deployed on the Google Cloud platform. However, with slight alterations the code should also run on a local machine or cluster of machines.



