---
title: AI weekly (46/2019)
subtitle: My selection of news on AI/ML and Data Science
date: 2019-11-15
# lastmod: 2019-11-29
bigimg: [{src: "/img/2019-11-15-ai-weekly-46-2019.jpg", desc: "Al Mirqab, near Cannes (2018)"}]
tags: ["ai-news", "gaussian-process", "intel", "microsoft", "ml-hardware", "nlp", "tensorflow"]
---

+++ Machine vision sees behind walls and in darkness +++ Deep Learning deciphers historical Japanese texts +++  Microsoft’s Vision AI Developer Kit is now generally available +++ Intel unleashes three new chips for AI work, challenging Nvidia +++ Looker seeks to go beyond business intelligence +++ Nasdaq is testing a deep learning system to monitor trading +++ The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design +++ Gaussian Processes, not quite for dummies +++ Self-training with Noisy Student improves ImageNet classification +++ Extensive list of NLP-Models implemented in Tensorflow +++ 74 Summaries of Machine Learning and NLP Research +++


<!--more-->

## Breakthrough &mdash; Or So They Say


**MIT's New Machine Vision Model Has Learned to See Behind Walls and in Darkness.** Published on [arXiv](https://arxiv.org/abs/1909.09300) and featured on [Technology Review](https://www.technologyreview.com/s/614470/machine-vision-has-learned-to-use-radio-waves-to-see-through-walls-and-in-darkness/), Tianhong Li and colleagues at MIT have found a way to teach a radio vision system to recognize people’s actions by training it with visible-light images. The new radio vision system can see what individuals are up to in a wide range of situations where visible-light imaging fails. From the abstract: " Our model takes radio frequency (RF) signals as input, generates 3D human skeletons as an intermediate representation, and recognizes actions and interactions of multiple people over time. By translating the input to an intermediate skeleton-based representation, our model can learn from both vision-based and RF-based datasets, and allow the two tasks to help each
other. We show that our model achieves comparable accuracy to vision-based action recognition systems in visible scenarios, yet continues to work accurately when people are not visible, hence addressing scenarios that are beyond the limit of today’s vision-based action recognition."


**How Machine Learning Can Help Unlock the World of Ancient Japan.** An article in the [The Gradient](https://thegradient.pub/machine-learning-ancient-japan/) features a deep learning approach to decipher historical Japanese texts. From 800 until 1900 CE, Japan used a writing system called Kuzushiji, which was removed from the curriculum in 1900 when the elementary school education was reformed. Currently, the overwhelming majority of Japanese speakers cannot read texts which are more than 150 years old. The volume of these texts — comprised of over three million books in storage but only readable by a handful of specially-trained scholars — is staggering. Now researchers from the National Institute of Informatics in Japan have created KuroNet, a Kuzushiji transcription model that is motivated by the idea of processing an entire page of text together, with the goal of capturing both long-range and local dependencies. In order to further improve the approach, a Kaggle contest was hosted using out-of-the-box detection algorithms such as Faster R-CNN and Cascade R-CNN. 



## Tools and Frameworks



**Microsoft’s Vision AI Developer Kit is now generally available.** The Vision AI Developer Kit, a hardware base built on Qualcomm’s Vision Intelligence Platform designed to run AI models locally and integrate with Microsoft’s Azure ML and Azure IoT Edge cloud services. Microsoft and Qualcomm now [announced](https://azure.microsoft.com/en-us/blog/microsoft-and-qualcomm-accelerate-ai-with-vision-ai-developer-kit/) that the [Vision AI Developer Kit](https://venturebeat.com/2019/09/03/microsofts-vision-ai-developer-kit-is-now-generally-available/) (made by eInfochips) is now broadly available from distributor Arrow Electronics for $249. A software development kit containing Visual Studio Code with Python modules, prebuilt Azure IoT deployment configurations, and a Vision AI Developer Kit extension for Visual Studio is on GitHub, along with a default module that recognizes upwards of 183 different objects. The Vision AI Developer Kit has a rival in Amazon’s [AWS DeepLens](https://venturebeat.com/2017/11/29/amazon-unveils-deeplens-a-249-camera-for-deep-learning/) and the [Google Coral Dev Board](https://venturebeat.com/2019/03/06/google-begins-selling-the-150-coral-dev-board-a-hardware-kit-for-accelerated-ai-edge-computing/).


**Intel unleashes three new chips for AI work, challenging Nvidia.** Intel introduced a trio of chips for training and deploying artificial intelligence models that will allow it to step up the competition against Nvidia, whose graphics processing units dominate the market. The chips grew out of Intel’s 2016 acquisitions of two machine learning companies, Nervana Systems and Movidius Ltd. More background [here](https://www.intel.ai/nnp-aisummit/#gs.fmldpp), [here](https://www.extremetech.com/computing/296990-intel-nervana-nnp-i-nnp-t-a-training-inference) and [here](https://siliconangle.com/2019/11/12/challenging-nvidia-intel-unleashes-new-chips-ai-training-inference/).


**With platform overhaul, Looker seeks to go beyond business intelligence.** The business intelligence company [announced major enhancements](https://siliconangle.com/2019/11/06/looker-seeks-go-beyond-business-intelligence-platform-overhaul/) to its platform that overhaul the user interface, improve integration with external applications and position it to go beyond visualizations to become an operational decision-making engine. Looker is adding a developer portal with an assortment of tools as well as support for several new languages, including Typescript/Javascript, R, Python, Kotlin and Swift. Looker is also adding integrations with Auger.ai machine learning and mParticle Inc.’s data orchestration. The other major enhancement area is in the user interface, where developers and users are getting greater flexibility to build customized experience. Dashboards are getting configurable filtering options such as cross-filtering, in which a change in one window dynamically affects others on the screen. Enhancements to SQL Runner, a front-end for the popular query language, make it possible for users to see visualization results interactively as they write a query. Looker 7 features will begin rolling out this month, with all features ready for customer testing by the end of the first quarter of 2020.



## Business News and Applications


**Nasdaq is testing a deep learning system to monitor trading.** 
For the first time, [Nasdaq](https://www.nasdaq.com/articles/for-the-first-time-nasdaq-is-using-artificial-intelligence-to-surveil-u.s.-stock-market) is applying artificial intelligence on its U.S. stock market to detect irregular and potentially malicious trading activity. The newly launched initiative aims to strengthen and revolutionize market surveillance through deep learning, transfer learning and human-in-the-loop learning.




## Publications


**The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design** ([arXiv:1911.05289](https://arxiv.org/abs/1911.05289)). A new paper by [Google's Jeff Dean](https://research.google/people/jeff/), from a talk at a recent conference. It is filled with interesting information about the intersection of chip design and ML. There is a section on machine-learning-specialized hardware with a good overview of the differences between a classic microprocessor and a TPU. 


**Gaussian Processes, not quite for dummies.** The Gradient features a [write-up](https://thegradient.pub/gaussian-process-not-quite-for-dummies/) by Yuge Shi of a [video lecture](https://youtu.be/92-98SYOdlY) by Richard Turner on the basics of Gaussian Processes, as a preparation for reading "the book" in this area, *Gaussian Processes for Machine Learning* by Carl Edward Rasmussen and Christopher K. I. Williams. 


**Neuroevolution: Evolve a New Path Toward Human Intelligence.** Neuroevolution, which combines neural networks with ideas drawn from Darwin, is gaining momentum. Its advocates claim that they can achieve faster, better results by generating a succession of new models, each slightly different than its predecessors, rather than relying on a purpose-built model. [Quanta magazine](https://www.quantamagazine.org/computers-evolve-a-new-path-toward-human-intelligence-20191106/) surveys the field, focusing on neuroevolution pioneer and Uber senior researcher Kenneth Stanley.


**Self-training with Noisy Student improves ImageNet classification** [(arXiv:1911.04252)](https://arxiv.org/abs/1911.04252). Self-training first uses labeled data to train a good teacher model, then use the teacher model to label unlabeled data and finally use the labeled data and unlabeled data to jointly train a student model. In typical self-training with the teacher-student framework, noise injection to the student is not used by default, or the role
of noise is not fully understood or justified. A team from Google Brain and CMU presents a simple self-training method that achieves 87.4% top-1 accuracy on ImageNet, which is 1.0% better than the state-of-the-art model. They first train an EfficientNet model on labeled ImageNet images and use it as a teacher to generate pseudo labels on 300M unlabeled images. Then they train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. They iterate this process by putting back the student as the teacher. During the generation of the pseudo labels, the teacher is not noised so that the pseudo labels are as good as possible. But during the learning of the student, noise is injected such as data augmentation, dropout, stochastic depth to the student so that the noised student is forced to learn harder from the pseudo labels.

**Data Science is Boring.** Many people cherrypick the exciting parts of doing Data Science (or ML, Machine Learning) to motivate themselves and others. But we must face a reality: the real work is often “boring” — boring as comparing to what people romanticize. Feeling bored creates tension; it, ultimately, leads to a high turnover rate in data science. [I want to share](https://towardsdatascience.com/data-science-is-boring-1d43473e353e) what I actually do and how I cope with the “boringness in data science”. I hope to help you, the aspiring Data Scientists, to set the right expectations.  


## Tutorials

**[GitHub] huseinzol05/NLP-Models-Tensorflow.** An extensive [list of NLP models](https://github.com/huseinzol05/NLP-Models-Tensorflow) implemented in TensorFlow. Gathers machine learning and tensorflow deep learning models for some 20+ NLP problems, arranged in Jupyter Notebooks. 

**74 Summaries of Machine Learning and NLP Research.** [Marek Rei](http://www.marekrei.com/), a lecturer at Imperial College London and a visiting researcher at the University of Cambridge, offers [74 summaries](http://www.marekrei.com/blog/74-summaries-of-machine-learning-and-nlp-research/?utm_campaign=Data_Elixir&utm_source=Data_Elixir_260) of machine learning and NLP research. A year earlier he has given another exposition on [57 earlier papers](http://www.marekrei.com/blog/paper-summaries/).